# åŒæ­¥å¼•æ“

## ğŸ“‹ æ–‡æ¡£è¯´æ˜

æœ¬æ–‡æ¡£è¯¦ç»†æè¿°åŒæ­¥å¼•æ“çš„è®¾è®¡å’Œå››ç§åŒæ­¥æ–¹å‘çš„å®ç°é€»è¾‘ã€‚

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2026-01-30  
**å®ç°çŠ¶æ€**: âœ… ESâ†’ES å·²å®Œæˆï¼Œå…¶ä»–è¿›è¡Œä¸­

---

## ğŸ¯ æ¦‚è¿°

åŒæ­¥å¼•æ“æ˜¯ DataTrac çš„æ ¸å¿ƒæ¨¡å—ï¼Œè´Ÿè´£æ‰§è¡Œå…·ä½“çš„æ•°æ®åŒæ­¥é€»è¾‘ã€‚

**æ”¯æŒçš„åŒæ­¥æ–¹å‘**:
1. MySQL â†’ Elasticsearch
2. Elasticsearch â†’ MySQL
3. MySQL â†’ MySQL
4. Elasticsearch â†’ Elasticsearch

---

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### æ¨¡å—ç»“æ„

```
sync_engine/
â”œâ”€â”€ mod.rs                      # å¼•æ“å…¥å£ (Pipeline å·¥å‚)
â”œâ”€â”€ framework/                  # æ ¸å¿ƒæ¡†æ¶ (åº•åº§)
â”‚   â”œâ”€â”€ mod.rs                  # Trait å®šä¹‰ (Reader/Writer/Transformer)
â”‚   â””â”€â”€ pipeline.rs             # ç®¡é“è°ƒåº¦é€»è¾‘
â”œâ”€â”€ plugins/                    # æ•°æ®æºæ’ä»¶ (Reader/Writer å®ç°)
â”‚   â”œâ”€â”€ mysql/
â”‚   â”œâ”€â”€ elasticsearch/
â”‚   â””â”€â”€ mongo/
â”œâ”€â”€ task_loader.rs              # ä»»åŠ¡é…ç½®åŠ è½½
â””â”€â”€ state_manager.rs            # ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸç®¡ç†
```

### SyncEngine ç»“æ„

```rust
pub struct SyncEngine {
    source_manager: Arc<DataSourceManager>,
    task_manager: Arc<TaskManager>,
    progress_monitor: Arc<ProgressMonitor>,
    // åŠ¨æ€ç”Ÿäº§ç®¡é“
    pipeline_factory: PipelineFactory,
}
```

---

## ğŸ”„ åŒæ­¥æµç¨‹ (åŸºäºç®¡é“)

### é€šç”¨æµç¨‹

```
1. å¯åŠ¨åŒæ­¥ä»»åŠ¡ (start_sync)
   â†“
2. åŠ è½½é…ç½® & åˆå§‹åŒ–å•å…ƒ (TaskLoader)
   â†“
3. ç»„è£…ç®¡é“ (PipelineFactory)
   â”œâ”€ åˆ›å»º Reader (e.g., MySQLReader)
   â”œâ”€ åˆ›å»º Writer (e.g., ElasticWriter)
   â””â”€ æ³¨å…¥ Transformers
   â†“
4. æäº¤ç»™ TaskManager è°ƒåº¦ (execute_auto_mode)
   â†“
5. ç®¡é“è¿è¡Œ (Pipeline.run)
   â”œâ”€ Reader è¯»æ‰¹æ¬¡ (DataRecord)
   â”œâ”€ Transformer å¤„ç†æ•°æ®
   â”œâ”€ Writer å†™æ‰¹æ¬¡
   â””â”€ ProgressMonitor æ›´æ–°è¿›åº¦
   â†“
6. ä»»åŠ¡å®Œæˆ
```

### æ ¸å¿ƒæ–¹æ³•

```rust
impl SyncEngine {
    // å¯åŠ¨åŒæ­¥
    pub async fn start_sync(&self, task_id: &str) -> Result<()>;
    
    // æš‚åœåŒæ­¥
    pub async fn pause_sync(&self, task_id: &str) -> Result<()>;
    
    // æ¢å¤åŒæ­¥
    pub async fn resume_sync(&self, task_id: &str) -> Result<()>;
    
    // åœæ­¢åŒæ­¥
    pub async fn stop_sync(&self, task_id: &str) -> Result<()>;
}
```

---

## ğŸ“Š å››ç§åŒæ­¥æ–¹å‘

### 1. Elasticsearch â†’ Elasticsearch

#### 1.1 æ¦‚è¿°

**ç”¨é€”**: åœ¨ä¸åŒ ES é›†ç¾¤ä¹‹é—´åŒæ­¥ç´¢å¼•æ•°æ®

**ç‰¹ç‚¹**:
- æ”¯æŒç´¢å¼•åç§°è½¬æ¢
- æ”¯æŒå¤šä¸ªæœç´¢æ¡ä»¶ç»„
- æ‰¹é‡é‡ç´¢å¼•
- æ•°æ®æ ¡éªŒ

#### 1.2 åŒæ­¥æµç¨‹

```
1. è·å–æºå’Œç›®æ ‡ ES å®¢æˆ·ç«¯
   â†“
2. TaskManager è‡ªåŠ¨æ¨¡å¼æ‰§è¡Œ
   â†“
3. ä¸ºæ¯ä¸ªç´¢å¼•æ‰§è¡ŒåŒæ­¥
   â”œâ”€ è·å–ç´¢å¼•æ€»æ–‡æ¡£æ•°
   â”œâ”€ è®¡ç®—æ‰¹æ¬¡æ•°
   â”œâ”€ å¾ªç¯å¤„ç†æ¯ä¸ªæ‰¹æ¬¡
   â”‚   â”œâ”€ ä½¿ç”¨ scroll API è¯»å–æ•°æ®
   â”‚   â”œâ”€ è½¬æ¢æ–‡æ¡£æ ¼å¼
   â”‚   â”œâ”€ ä½¿ç”¨ bulk API å†™å…¥
   â”‚   â””â”€ æ›´æ–°è¿›åº¦
   â”œâ”€ æ•°æ®æ ¡éªŒï¼ˆå¯¹æ¯”æ–‡æ¡£æ•°ï¼‰
   â””â”€ æ ‡è®°å®Œæˆ
   â†“
4. æ‰€æœ‰ç´¢å¼•å®Œæˆ
```

#### 1.3 æ ¸å¿ƒä»£ç 

```rust
pub async fn sync_es_to_es(
    engine: &SyncEngine,
    config: &SyncTaskConfig,
) -> Result<()> {
    // 1. è·å–å®¢æˆ·ç«¯
    let source_client = engine.get_es_client(&config.source_id).await?;
    let target_client = engine.get_es_client(&config.target_id).await?;
    
    // 2. è·å–ç´¢å¼•åˆ—è¡¨
    let indices = config.es_config.as_ref()
        .and_then(|c| c.selected_indices.as_ref())
        .ok_or_else(|| anyhow!("æœªé…ç½®ç´¢å¼•"))?;
    
    // 3. ä½¿ç”¨ TaskManager è‡ªåŠ¨æ¨¡å¼æ‰§è¡Œ
    let success_count = engine.task_manager.execute_auto_mode(
        &config.task_id,
        config.sync_config.thread_count as usize,
        engine.progress_monitor.clone(),
        |unit_id, unit_name| {
            let source = source_client.clone();
            let target = target_client.clone();
            let cfg = config.clone();
            let monitor = engine.progress_monitor.clone();
            let manager = engine.task_manager.clone();
            
            async move {
                sync_single_index(
                    &source,
                    &target,
                    &unit_name,
                    &cfg,
                    &manager,
                    &monitor,
                ).await
            }
        }
    ).await?;
    
    log::info!("ESâ†’ES åŒæ­¥å®Œæˆï¼ŒæˆåŠŸ: {}/{}", success_count, indices.len());
    Ok(())
}

async fn sync_single_index(
    source_client: &Elasticsearch,
    target_client: &Elasticsearch,
    index_name: &str,
    config: &SyncTaskConfig,
    task_manager: &TaskManager,
    progress_monitor: &Arc<ProgressMonitor>,
) -> Result<()> {
    let task_id = &config.task_id;
    let batch_size = config.sync_config.batch_size as usize;
    
    // 1. è·å–æ€»æ–‡æ¡£æ•°
    let count_response = source_client.count(CountParts::Index(&[index_name]))
        .send().await?;
    let total_count = count_response.json::<serde_json::Value>().await?
        ["count"].as_u64().unwrap_or(0);
    
    // 2. æ›´æ–°æ€»è®°å½•æ•°
    task_manager.update_unit_progress_with_sync(
        task_id,
        index_name,
        total_count,
        0,
        progress_monitor,
    ).await?;
    
    // 3. æ‰¹æ¬¡åŒæ­¥
    let total_batches = (total_count as usize + batch_size - 1) / batch_size;
    let mut processed = 0u64;
    let mut scroll_id: Option<String> = None;
    
    for batch_num in 1..=total_batches {
        // è¯»å–æ‰¹æ¬¡æ•°æ®
        let (docs, new_scroll_id) = if batch_num == 1 {
            // ç¬¬ä¸€æ‰¹ï¼šåˆå§‹åŒ– scroll
            let response = source_client.search(SearchParts::Index(&[index_name]))
                .scroll("5m")
                .size(batch_size as i64)
                .send().await?;
            
            let body = response.json::<serde_json::Value>().await?;
            let docs = extract_documents(&body);
            let scroll_id = body["_scroll_id"].as_str().map(String::from);
            
            (docs, scroll_id)
        } else {
            // åç»­æ‰¹æ¬¡ï¼šä½¿ç”¨ scroll
            let response = source_client.scroll(ScrollParts::None)
                .scroll_id(scroll_id.as_ref().unwrap())
                .scroll("5m")
                .send().await?;
            
            let body = response.json::<serde_json::Value>().await?;
            let docs = extract_documents(&body);
            let scroll_id = body["_scroll_id"].as_str().map(String::from);
            
            (docs, scroll_id)
        };
        
        scroll_id = new_scroll_id;
        
        if docs.is_empty() {
            break;
        }
        
        // å†™å…¥ç›®æ ‡
        bulk_index(target_client, index_name, &docs).await?;
        
        // æ›´æ–°è¿›åº¦
        processed += docs.len() as u64;
        task_manager.update_unit_progress_with_sync(
            task_id,
            index_name,
            total_count,
            processed,
            progress_monitor,
        ).await?;
        
        // æ·»åŠ æ—¥å¿—
        progress_monitor.add_log(
            task_id,
            LogLevel::Info,
            LogCategory::Realtime,
            format!("å·²åŒæ­¥ {} / {} æ¡è®°å½• ({:.1}%)", 
                processed, total_count, 
                (processed as f64 / total_count as f64) * 100.0)
        );
    }
    
    // 4. æ¸…ç† scroll
    if let Some(scroll_id) = scroll_id {
        let _ = source_client.clear_scroll(ClearScrollParts::None)
            .scroll_id(&[scroll_id])
            .send().await;
    }
    
    // 5. æ•°æ®æ ¡éªŒ
    let target_count = get_index_count(target_client, index_name).await?;
    if target_count == total_count {
        progress_monitor.add_log(
            task_id,
            LogLevel::Info,
            LogCategory::Verify,
            format!("âœ“ ç´¢å¼• {} æ•°æ®æ ¡éªŒé€šè¿‡ï¼šæº {} æ¡ = ç›®æ ‡ {} æ¡", 
                index_name, total_count, target_count)
        );
    } else {
        anyhow::bail!("æ•°æ®æ ¡éªŒå¤±è´¥ï¼šæº {} æ¡ != ç›®æ ‡ {} æ¡", total_count, target_count);
    }
    
    Ok(())
}
```

#### 1.4 å…³é”®æŠ€æœ¯ç‚¹

**Scroll API**:
- ç”¨äºåˆ†é¡µè¯»å–å¤§é‡æ•°æ®
- ä¿æŒæœç´¢ä¸Šä¸‹æ–‡ 5 åˆ†é’Ÿ
- è¯»å–å®Œæˆåæ¸…ç† scroll

**Bulk API**:
- æ‰¹é‡å†™å…¥æ–‡æ¡£
- æé«˜å†™å…¥æ€§èƒ½
- å¤„ç†éƒ¨åˆ†å¤±è´¥æƒ…å†µ

**æ•°æ®æ ¡éªŒ**:
- å¯¹æ¯”æºå’Œç›®æ ‡æ–‡æ¡£æ•°
- ç¡®ä¿æ•°æ®å®Œæ•´æ€§

---

### 2. MySQL â†’ MySQL

#### 2.1 æ¦‚è¿°

**ç”¨é€”**: åœ¨ä¸åŒ MySQL æ•°æ®åº“ä¹‹é—´åŒæ­¥è¡¨æ•°æ®

**ç‰¹ç‚¹**:
- æ”¯æŒæ•°æ®åº“åç§°è½¬æ¢
- æ”¯æŒè¡¨ç»“æ„è‡ªåŠ¨åˆ›å»º
- æ‰¹é‡æ•°æ®ä¼ è¾“
- æ”¯æŒå¤šç§è¡¨å­˜åœ¨ç­–ç•¥

#### 2.2 åŒæ­¥æµç¨‹

```
1. è·å–æºå’Œç›®æ ‡ MySQL è¿æ¥æ± 
   â†“
2. TaskManager è‡ªåŠ¨æ¨¡å¼æ‰§è¡Œ
   â†“
3. ä¸ºæ¯ä¸ªè¡¨æ‰§è¡ŒåŒæ­¥
   â”œâ”€ å¤„ç†æ•°æ®åº“åç§°è½¬æ¢
   â”œâ”€ è·å–è¡¨ç»“æ„
   â”œâ”€ åœ¨ç›®æ ‡åˆ›å»ºè¡¨ï¼ˆæ ¹æ®ç­–ç•¥ï¼‰
   â”œâ”€ è·å–è¡¨æ€»è¡Œæ•°
   â”œâ”€ è®¡ç®—æ‰¹æ¬¡æ•°
   â”œâ”€ å¾ªç¯å¤„ç†æ¯ä¸ªæ‰¹æ¬¡
   â”‚   â”œâ”€ ä½¿ç”¨ LIMIT OFFSET è¯»å–æ•°æ®
   â”‚   â”œâ”€ è½¬æ¢æ•°æ®æ ¼å¼
   â”‚   â”œâ”€ ä½¿ç”¨ INSERT æ‰¹é‡å†™å…¥
   â”‚   â””â”€ æ›´æ–°è¿›åº¦
   â”œâ”€ æ•°æ®æ ¡éªŒï¼ˆå¯¹æ¯”è¡Œæ•°ï¼‰
   â””â”€ æ ‡è®°å®Œæˆ
   â†“
4. æ‰€æœ‰è¡¨å®Œæˆ
```

#### 2.3 æ ¸å¿ƒä»£ç ç»“æ„

```rust
pub async fn sync_mysql_to_mysql(
    engine: &SyncEngine,
    config: &SyncTaskConfig,
) -> Result<()> {
    // 1. è·å–è¿æ¥æ± 
    let source_pool = engine.get_mysql_pool(&config.source_id).await?;
    let target_pool = engine.get_mysql_pool(&config.target_id).await?;
    
    // 2. ä½¿ç”¨ TaskManager è‡ªåŠ¨æ¨¡å¼æ‰§è¡Œ
    let success_count = engine.task_manager.execute_auto_mode(
        &config.task_id,
        config.sync_config.thread_count as usize,
        engine.progress_monitor.clone(),
        |unit_id, unit_name| {
            // æ‰§è¡Œå•è¡¨åŒæ­¥
            sync_single_table(...)
        }
    ).await?;
    
    Ok(())
}

async fn sync_single_table(...) -> Result<()> {
    // 1. è§£æè¡¨åï¼ˆdatabase.tableï¼‰
    let (source_db, table_name) = parse_table_name(&unit_name)?;
    
    // 2. åº”ç”¨æ•°æ®åº“åç§°è½¬æ¢
    let target_db = apply_db_name_transform(source_db, &config.sync_config.db_name_transform)?;
    
    // 3. è·å–è¡¨ç»“æ„
    let table_schema = get_table_schema(&source_pool, source_db, table_name).await?;
    
    // 4. åœ¨ç›®æ ‡åˆ›å»ºè¡¨
    create_target_table(&target_pool, target_db, table_name, &table_schema, &config.sync_config.table_exists_strategy).await?;
    
    // 5. è·å–æ€»è¡Œæ•°
    let total_count = get_table_count(&source_pool, source_db, table_name).await?;
    
    // 6. æ‰¹æ¬¡åŒæ­¥
    let batch_size = config.sync_config.batch_size as usize;
    let total_batches = (total_count + batch_size - 1) / batch_size;
    
    for batch_num in 0..total_batches {
        let offset = batch_num * batch_size;
        
        // è¯»å–æ‰¹æ¬¡æ•°æ®
        let rows = fetch_batch(&source_pool, source_db, table_name, offset, batch_size).await?;
        
        // å†™å…¥ç›®æ ‡
        insert_batch(&target_pool, target_db, table_name, &rows).await?;
        
        // æ›´æ–°è¿›åº¦
        let processed = (batch_num + 1) * batch_size;
        task_manager.update_unit_progress_with_sync(...).await?;
    }
    
    // 7. æ•°æ®æ ¡éªŒ
    let target_count = get_table_count(&target_pool, target_db, table_name).await?;
    verify_counts(total_count, target_count)?;
    
    Ok(())
}
```

#### 2.4 å…³é”®æŠ€æœ¯ç‚¹

**è¡¨ç»“æ„å¤åˆ¶**:
```rust
async fn get_table_schema(pool: &MySqlPool, db: &str, table: &str) -> Result<String> {
    let query = format!("SHOW CREATE TABLE `{}`.`{}`", db, table);
    let row: (String, String) = sqlx::query_as(&query)
        .fetch_one(pool).await?;
    Ok(row.1) // CREATE TABLE è¯­å¥
}
```

**è¡¨å­˜åœ¨ç­–ç•¥**:
```rust
async fn create_target_table(
    pool: &MySqlPool,
    db: &str,
    table: &str,
    schema: &str,
    strategy: &TableExistsStrategy,
) -> Result<()> {
    match strategy {
        TableExistsStrategy::Drop => {
            // åˆ é™¤é‡å»º
            sqlx::query(&format!("DROP TABLE IF EXISTS `{}`.`{}`", db, table))
                .execute(pool).await?;
            sqlx::query(schema).execute(pool).await?;
        }
        TableExistsStrategy::Truncate => {
            // æ¸…ç©ºæ•°æ®
            sqlx::query(&format!("TRUNCATE TABLE `{}`.`{}`", db, table))
                .execute(pool).await?;
        }
        TableExistsStrategy::Backup => {
            // å¤‡ä»½ååˆ é™¤é‡å»º
            let backup_table = format!("{}_{}", table, chrono::Utc::now().timestamp());
            sqlx::query(&format!("RENAME TABLE `{}`.`{}` TO `{}`.`{}`", db, table, db, backup_table))
                .execute(pool).await?;
            sqlx::query(schema).execute(pool).await?;
        }
    }
    Ok(())
}
```

**æ•°æ®åº“åç§°è½¬æ¢**:
```rust
fn apply_db_name_transform(
    source_db: &str,
    transform: &Option<DbNameTransform>,
) -> Result<String> {
    if let Some(t) = transform {
        if !t.enabled {
            return Ok(source_db.to_string());
        }
        
        match t.mode.as_str() {
            "prefix" => {
                // æ›¿æ¢å‰ç¼€
                if source_db.starts_with(&t.source_pattern) {
                    Ok(source_db.replacen(&t.source_pattern, &t.target_pattern, 1))
                } else {
                    Ok(source_db.to_string())
                }
            }
            "suffix" => {
                // æ›¿æ¢åç¼€
                if source_db.ends_with(&t.source_pattern) {
                    let len = source_db.len() - t.source_pattern.len();
                    Ok(format!("{}{}", &source_db[..len], t.target_pattern))
                } else {
                    Ok(source_db.to_string())
                }
            }
            _ => Ok(source_db.to_string())
        }
    } else {
        Ok(source_db.to_string())
    }
}
```

---

### 3. MySQL â†’ Elasticsearch

#### 3.1 æ¦‚è¿°

**ç”¨é€”**: å°† MySQL è¡¨æ•°æ®åŒæ­¥åˆ° ES ç´¢å¼•

**ç‰¹ç‚¹**:
- è‡ªåŠ¨ç±»å‹æ˜ å°„ï¼ˆMySQL â†’ ESï¼‰
- æ”¯æŒæ‰¹é‡ç´¢å¼•
- æ•°æ®è½¬æ¢å’Œæ¸…æ´—

#### 3.2 åŒæ­¥æµç¨‹

```
1. è·å–æº MySQL è¿æ¥æ± å’Œç›®æ ‡ ES å®¢æˆ·ç«¯
   â†“
2. TaskManager è‡ªåŠ¨æ¨¡å¼æ‰§è¡Œ
   â†“
3. ä¸ºæ¯ä¸ªè¡¨æ‰§è¡ŒåŒæ­¥
   â”œâ”€ è·å–è¡¨ç»“æ„
   â”œâ”€ ç”Ÿæˆ ES mapping
   â”œâ”€ åˆ›å»º ES ç´¢å¼•
   â”œâ”€ è·å–è¡¨æ€»è¡Œæ•°
   â”œâ”€ è®¡ç®—æ‰¹æ¬¡æ•°
   â”œâ”€ å¾ªç¯å¤„ç†æ¯ä¸ªæ‰¹æ¬¡
   â”‚   â”œâ”€ è¯»å– MySQL æ•°æ®
   â”‚   â”œâ”€ è½¬æ¢ä¸º JSON æ–‡æ¡£
   â”‚   â”œâ”€ ä½¿ç”¨ bulk API å†™å…¥ ES
   â”‚   â””â”€ æ›´æ–°è¿›åº¦
   â”œâ”€ æ•°æ®æ ¡éªŒ
   â””â”€ æ ‡è®°å®Œæˆ
   â†“
4. æ‰€æœ‰è¡¨å®Œæˆ
```

#### 3.3 ç±»å‹æ˜ å°„

| MySQL ç±»å‹ | ES ç±»å‹ |
|-----------|---------|
| INT, BIGINT | long |
| FLOAT, DOUBLE | double |
| VARCHAR, TEXT | text + keyword |
| DATE | date |
| DATETIME, TIMESTAMP | date |
| BOOLEAN | boolean |

---

### 4. Elasticsearch â†’ MySQL

#### 4.1 æ¦‚è¿°

**ç”¨é€”**: å°† ES ç´¢å¼•æ•°æ®åŒæ­¥åˆ° MySQL è¡¨

**ç‰¹ç‚¹**:
- è‡ªåŠ¨ç±»å‹æ˜ å°„ï¼ˆES â†’ MySQLï¼‰
- æ”¯æŒç´¢å¼•æ¨¡å¼åŒ¹é…
- æ‰¹é‡æ•°æ®å†™å…¥

#### 4.2 åŒæ­¥æµç¨‹

```
1. è·å–æº ES å®¢æˆ·ç«¯å’Œç›®æ ‡ MySQL è¿æ¥æ± 
   â†“
2. TaskManager è‡ªåŠ¨æ¨¡å¼æ‰§è¡Œ
   â†“
3. ä¸ºæ¯ä¸ªç´¢å¼•æ‰§è¡ŒåŒæ­¥
   â”œâ”€ è·å–ç´¢å¼• mapping
   â”œâ”€ ç”Ÿæˆ MySQL è¡¨ç»“æ„
   â”œâ”€ åˆ›å»º MySQL è¡¨
   â”œâ”€ è·å–ç´¢å¼•æ€»æ–‡æ¡£æ•°
   â”œâ”€ è®¡ç®—æ‰¹æ¬¡æ•°
   â”œâ”€ å¾ªç¯å¤„ç†æ¯ä¸ªæ‰¹æ¬¡
   â”‚   â”œâ”€ ä½¿ç”¨ scroll API è¯»å– ES æ•°æ®
   â”‚   â”œâ”€ è½¬æ¢ä¸º MySQL è¡Œ
   â”‚   â”œâ”€ æ‰¹é‡ INSERT
   â”‚   â””â”€ æ›´æ–°è¿›åº¦
   â”œâ”€ æ•°æ®æ ¡éªŒ
   â””â”€ æ ‡è®°å®Œæˆ
   â†“
4. æ‰€æœ‰ç´¢å¼•å®Œæˆ
```

#### 4.3 ç±»å‹æ˜ å°„

| ES ç±»å‹ | MySQL ç±»å‹ |
|---------|-----------|
| long | BIGINT |
| integer | INT |
| double | DOUBLE |
| text, keyword | VARCHAR(255) |
| date | DATETIME |
| boolean | TINYINT(1) |

---

## ğŸ”§ é€šç”¨å·¥å…·å‡½æ•°

### MySQL å·¥å…·

```rust
// è·å–è¡¨è¡Œæ•°
async fn get_table_count(pool: &MySqlPool, db: &str, table: &str) -> Result<u64>;

// è·å–è¡¨ç»“æ„
async fn get_table_schema(pool: &MySqlPool, db: &str, table: &str) -> Result<String>;

// æ‰¹é‡è¯»å–æ•°æ®
async fn fetch_batch(pool: &MySqlPool, db: &str, table: &str, offset: usize, limit: usize) -> Result<Vec<Row>>;

// æ‰¹é‡æ’å…¥æ•°æ®
async fn insert_batch(pool: &MySqlPool, db: &str, table: &str, rows: &[Row]) -> Result<()>;
```

### ES å·¥å…·

```rust
// è·å–ç´¢å¼•æ–‡æ¡£æ•°
async fn get_index_count(client: &Elasticsearch, index: &str) -> Result<u64>;

// è·å–ç´¢å¼• mapping
async fn get_index_mapping(client: &Elasticsearch, index: &str) -> Result<serde_json::Value>;

// æ‰¹é‡ç´¢å¼•æ–‡æ¡£
async fn bulk_index(client: &Elasticsearch, index: &str, docs: &[serde_json::Value]) -> Result<()>;

// æå–æ–‡æ¡£
fn extract_documents(response: &serde_json::Value) -> Vec<serde_json::Value>;
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [ä»»åŠ¡ç®¡ç†å™¨](./ä»»åŠ¡ç®¡ç†å™¨.md) - TaskManager è®¾è®¡
- [ä»»åŠ¡è°ƒåº¦ä¸æ–­ç‚¹ç»­ä¼ ](./ä»»åŠ¡è°ƒåº¦ä¸æ–­ç‚¹ç»­ä¼ .md) - è°ƒåº¦æœºåˆ¶
- [è‡ªåŠ¨æ¨¡å¼å®ç°](../implementation/è‡ªåŠ¨æ¨¡å¼å®ç°.md) - è‡ªåŠ¨æ¨¡å¼æ‰§è¡Œæµç¨‹
- [å®æ–½æŒ‡å—](../implementation/å®æ–½æŒ‡å—.md) - åŒæ­¥å¼•æ“å®æ–½æ­¥éª¤

---

**æ–‡æ¡£ç»´æŠ¤**: DataTrac å¼€å‘å›¢é˜Ÿ  
**æœ€åæ›´æ–°**: 2026-01-30
